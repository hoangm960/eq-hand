{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01f8cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47d0f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(detectionCon=0.8, maxHands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9138a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE = {\n",
    "    \"bass\": [0, 0, 0, 0, 0],\n",
    "    \"mid\": [0, 1, 0, 0, 0],\n",
    "    \"treble\": [0, 0, 0, 0, 1],\n",
    "    \"all\": [1, 1, 1, 1, 1],\n",
    "    \"toggle\": [1, 1, 0, 0, 1]  # gesture to turn on/off adjustment mode\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d0de21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_RANGE = [0, 100]\n",
    "VOLUME_RANGE = (-50, 50)\n",
    "INITIAL_VOLUME_ANGLE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'playlist/Butterfly.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97ed265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(audio_file):\n",
    "    print(\"File exists!\")\n",
    "else:\n",
    "    print(\"File not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd66d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meng\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-7.1.1-full_build\\bin\\ffmpeg.exe\n"
     ]
    }
   ],
   "source": [
    "from pydub.utils import which\n",
    "print(which(\"ffmpeg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7227ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
      "d:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
      "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
      "d:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
      "d:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
      "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Butterfly.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAudioPlayer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioPlayer\n\u001b[32m      4\u001b[39m eq_controller = EQController()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m player = \u001b[43mAudioPlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq_controller\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m adjust_mode = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      8\u001b[39m prev_toggle_state = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# to prevent flipping too fast\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\AudioPlayer.py:11\u001b[39m, in \u001b[36mAudioPlayer.__init__\u001b[39m\u001b[34m(self, filename, eq_controller)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, eq_controller):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mself\u001b[39m.eq_controller = eq_controller\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28mself\u001b[39m.audio = \u001b[43mAudioSegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_mp3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m.set_channels(\u001b[32m1\u001b[39m).set_frame_rate(\u001b[32m44100\u001b[39m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mself\u001b[39m.samples = np.array(\u001b[38;5;28mself\u001b[39m.audio.get_array_of_samples()).astype(\n\u001b[32m     14\u001b[39m         np.float32) / \u001b[32m32768.0\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m.fs = \u001b[32m44100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:796\u001b[39m, in \u001b[36mAudioSegment.from_mp3\u001b[39m\u001b[34m(cls, file, parameters)\u001b[39m\n\u001b[32m    794\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_mp3\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmp3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:651\u001b[39m, in \u001b[36mAudioSegment.from_file\u001b[39m\u001b[34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[39m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    650\u001b[39m     filename = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m file, close_file = \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[32m    654\u001b[39m     \u001b[38;5;28mformat\u001b[39m = \u001b[38;5;28mformat\u001b[39m.lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\School\\OneDrive - Fulbright University Vietnam\\ComVi\\eq-hand\\.venv\\Lib\\site-packages\\pydub\\utils.py:60\u001b[39m, in \u001b[36m_fd_or_path_or_tempfile\u001b[39m\u001b[34m(fd, mode, tempfile)\u001b[39m\n\u001b[32m     57\u001b[39m     close_fd = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     fd = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     close_fd = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Butterfly.mp3'"
     ]
    }
   ],
   "source": [
    "from EqController import EQController\n",
    "from AudioPlayer import AudioPlayer\n",
    "\n",
    "eq_controller = EQController()\n",
    "player = AudioPlayer(audio_file, eq_controller)\n",
    "\n",
    "adjust_mode = False\n",
    "prev_toggle_state = False  # to prevent flipping too fast\n",
    "toggle_cooldown = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "threading.Thread(target=player.play).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if len(hands) == 2:\n",
    "        hand1, hand2 = hands\n",
    "        if hand1[\"center\"][0] < hand2[\"center\"][0]:\n",
    "            left_hand = hand2\n",
    "            right_hand = hand1\n",
    "        else:\n",
    "            left_hand = hand1\n",
    "            right_hand = hand2\n",
    "\n",
    "        fingers_left = detector.fingersUp(left_hand)\n",
    "        # == Adjustment Mode ==\n",
    "        if fingers_left == GESTURE[\"toggle\"]:\n",
    "            if not prev_toggle_state and toggle_cooldown == 0:\n",
    "                adjust_mode = not adjust_mode\n",
    "                toggle_cooldown = 20 # frames to prevent spamming toggle\n",
    "            prev_toggle_state = True\n",
    "        else:\n",
    "            prev_toggle_state = False\n",
    "\n",
    "        if toggle_cooldown > 0:\n",
    "            toggle_cooldown -= 1\n",
    "\n",
    "        # == EQ and Volume Control ==\n",
    "        freq_band = \"none\" # default\n",
    "        gain = 1.0 # default\n",
    "        volume = 1.0 # default\n",
    "        if adjust_mode:\n",
    "            for control, gesture in GESTURE.items():\n",
    "                if fingers_left == gesture:\n",
    "                    freq_band = control\n",
    "\n",
    "                    if control == \"all\": # adjust the volume\n",
    "                        wrist = np.array(right_hand['lmList'][0])\n",
    "                        middle_tip = np.array(right_hand['lmList'][12])\n",
    "\n",
    "                        dx = middle_tip[0] - wrist[0]\n",
    "                        dy = middle_tip[1] - wrist[1]\n",
    "                        angle = -math.degrees(math.atan2(dy, dx)) - INITIAL_VOLUME_ANGLE\n",
    "                        angle_clamped = max(\n",
    "                            VOLUME_RANGE[0], min(VOLUME_RANGE[1], angle))\n",
    "\n",
    "                        volume = (angle_clamped - VOLUME_RANGE[0]) / (VOLUME_RANGE[1] - VOLUME_RANGE[0])\n",
    "                        player.set_volume(volume)\n",
    "                        player.get_volume()\n",
    "\n",
    "\n",
    "                    else: # adjust the eq\n",
    "                        distance, info, img = detector.findDistance(\n",
    "                            right_hand[\"lmList\"][8][:-1],\n",
    "                            right_hand[\"lmList\"][4][:-1],\n",
    "                            img\n",
    "                        )\n",
    "                        gain = max(EQ_RANGE[0], min(EQ_RANGE[1], int(distance * 0.5)))/100\n",
    "                        # set band name\n",
    "                        eq_controller.set_band(control)\n",
    "                        eq_controller.set_gain(gain)\n",
    "                        # assign band name and gain\n",
    "                        freq_band = eq_controller.get_selected_band()\n",
    "                        gain = eq_controller.get_gains()\n",
    "                    break\n",
    "\n",
    "        cv2.putText(img, f\"Freq Band: {freq_band}\", (10, 70),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3,)\n",
    "        cv2.putText(img, f\"Gain: {gain}\", (10, 110),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3,)\n",
    "        cv2.putText(img, f\"Volume: {int(volume*100)} %\", (10, 150),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3,)\n",
    "        cv2.putText(img, f\"Adjust Mode: {'ON' if adjust_mode else 'OFF'}\", (10, 190),\n",
    "            cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0) if adjust_mode else (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Equalizer Control\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        player.stop()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
