{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01f8cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d0f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(detectionCon=0.8, maxHands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9138a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE = {\n",
    "    \"bass\": [0, 0, 0, 0, 0],\n",
    "    \"mid\": [0, 1, 0, 0, 0],\n",
    "    \"treble\": [0, 0, 0, 0, 1],\n",
    "    \"all\": [1, 1, 1, 1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d0de21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_RANGE = [0, 100]\n",
    "VOLUME_RANGE = (-50, 50)\n",
    "INITIAL_VOLUME_ANGLE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e30df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if len(hands) == 2:\n",
    "        hand1, hand2 = hands\n",
    "        if hand1[\"center\"][0] < hand2[\"center\"][0]:\n",
    "            left_hand = hand2\n",
    "            right_hand = hand1\n",
    "        else:\n",
    "            left_hand = hand1\n",
    "            right_hand = hand2\n",
    "\n",
    "        fingers_left = detector.fingersUp(left_hand)\n",
    "        freq_band = \"none\"\n",
    "        gain = 0\n",
    "        for control, gesture in GESTURE.items():\n",
    "            if fingers_left == gesture:\n",
    "                freq_band = control\n",
    "\n",
    "                if control == \"all\":\n",
    "                    wrist = np.array(right_hand['lmList'][0])\n",
    "                    middle_tip = np.array(right_hand['lmList'][12])\n",
    "\n",
    "                    dx = middle_tip[0] - wrist[0]\n",
    "                    dy = middle_tip[1] - wrist[1]\n",
    "                    angle = -math.degrees(math.atan2(dy, dx)) - INITIAL_VOLUME_ANGLE\n",
    "                    angle_clamped = max(\n",
    "                        VOLUME_RANGE[0], min(VOLUME_RANGE[1], angle))\n",
    "                    gain = int(angle_clamped)\n",
    "                else:\n",
    "                    distance, info, img = detector.findDistance(\n",
    "                        right_hand[\"lmList\"][8][:-1],\n",
    "                        right_hand[\"lmList\"][4][:-1],\n",
    "                        img\n",
    "                    )\n",
    "                    gain = max(EQ_RANGE[0], min(EQ_RANGE[1], int(distance * 0.5)))\n",
    "                break\n",
    "\n",
    "        cv2.putText(img, f\"Freq Band: {freq_band}\", (10, 70),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3,)\n",
    "        cv2.putText(img, f\"Gain: {gain}\", (10, 110),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3,)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Equalizer Control\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
